{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aabe23a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder = ['P', 'S', 'E', 'U', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '+', '-', '*', '/', '.', ':', '=', '_']\n",
      "encoder = {'P': 0, 'S': 1, 'E': 2, 'U': 3, '0': 4, '1': 5, '2': 6, '3': 7, '4': 8, '5': 9, '6': 10, '7': 11, '8': 12, '9': 13, '+': 14, '-': 15, '*': 16, '/': 17, '.': 18, ':': 19, '=': 20, '_': 21}\n",
      "length check: True\n",
      "22\n",
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'S12.93=-25.15+-23.54+61.62E'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run common.ipynb\n",
    "\n",
    "tokenizer.decode(tokenizer.get_data(third_number=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e940d0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_ids': tensor([[ 1, 10,  5,  ...,  0,  0,  0],\n",
       "          [ 1, 11, 11,  ...,  0,  0,  0],\n",
       "          [ 1,  5, 13,  ...,  2,  0,  0],\n",
       "          ...,\n",
       "          [ 1, 15,  6,  ...,  0,  0,  0],\n",
       "          [ 1, 13,  7,  ...,  0,  0,  0],\n",
       "          [ 1, 15, 11,  ...,  0,  0,  0]], device='cuda:0'),\n",
       "  'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 1, 0, 0],\n",
       "          ...,\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'),\n",
       "  'label': tensor([[-100, -100, -100,  ..., -100, -100, -100],\n",
       "          [-100, -100, -100,  ..., -100, -100, -100],\n",
       "          [-100, -100, -100,  ...,    2, -100, -100],\n",
       "          ...,\n",
       "          [-100, -100, -100,  ..., -100, -100, -100],\n",
       "          [-100, -100, -100,  ..., -100, -100, -100],\n",
       "          [-100, -100, -100,  ..., -100, -100, -100]], device='cuda:0')},\n",
       " {'input_ids': tensor([[ 1, 10,  5,  ...,  0,  0,  0],\n",
       "          [ 1, 11, 11,  ...,  0,  0,  0],\n",
       "          [ 1,  5, 13,  ...,  0,  0,  0],\n",
       "          ...,\n",
       "          [ 1, 15,  6,  ...,  0,  0,  0],\n",
       "          [ 1, 13,  7,  ...,  0,  0,  0],\n",
       "          [ 1, 15, 11,  ...,  0,  0,  0]], device='cuda:0'),\n",
       "  'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'),\n",
       "  'label': tensor([[-100, -100, -100,  ..., -100, -100, -100],\n",
       "          [-100, -100, -100,  ..., -100, -100, -100],\n",
       "          [-100, -100, -100,  ..., -100, -100, -100],\n",
       "          ...,\n",
       "          [-100, -100, -100,  ..., -100, -100, -100],\n",
       "          [-100, -100, -100,  ..., -100, -100, -100],\n",
       "          [-100, -100, -100,  ..., -100, -100, -100]], device='cuda:0')})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "构造一个批次的训练数据, 包括 正确回答: choice 和 错误回答: reject\n",
    "并对每个样本进行填充、构造注意力掩码和标签, 使得模型在训练时只关注答案部分\n",
    "'''\n",
    "def get_batch_data():\n",
    "\n",
    "    def pad(data, split, lens):\n",
    "        # 做个白板\n",
    "        input_ids = torch.full(\n",
    "            (len(data), lens),\n",
    "            tokenizer.encoder['P'],\n",
    "            device=device\n",
    "        )  # -> (batch_size, lens)\n",
    "\n",
    "        # 往白板里黏贴数据\n",
    "        for i, d in enumerate(data):\n",
    "            input_ids[i, :len(d)] = torch.LongTensor(d)\n",
    "\n",
    "        attention_mask = (input_ids != tokenizer.encoder['P']).long()\n",
    "\n",
    "        # 计算label\n",
    "        label = input_ids.clone()\n",
    "        for l, s in zip(label, split):\n",
    "            # 将序列前 s 个位置, 通常为问题部, 以及所有填充位置都设为 -100\n",
    "            l[:s] = -100  # 问题\n",
    "            l[l == tokenizer.encoder['P']] = -100\n",
    "\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'label': label\n",
    "        }\n",
    "\n",
    "    # 正确的问答\n",
    "    # 设定为 三数求和\n",
    "    choice = [tokenizer.get_data(third_number=True) for i in range(64)]\n",
    "\n",
    "    # 分隔位置\n",
    "    # 对每个生成的序列，找到等号 '=' 在序列中的位置，并加 1。\n",
    "    # 这个位置将作为问题和答案的分界线，前面的部分代表问题，后面的部分代表答案\n",
    "    split = [i.index(tokenizer.encoder['=']) + 1 for i in choice]\n",
    "\n",
    "    # 错误的回答 简单地定义为空回答就可以了\n",
    "    reject = [d[:s] for d, s in zip(choice, split)]  # 取每个回答的问题部分\n",
    "    reject = [i + [tokenizer.encoder['E']] for i in reject]  # 将答案部分填充为 End\n",
    "\n",
    "    # 求最大长度\n",
    "    lens = max([len(i) for i in choice])\n",
    "    # print([x.shape for x in pad(choice, split, lens).values()])\n",
    "    # print([x.shape for x in pad(reject, split, lens).values()])\n",
    "    return pad(choice, split, lens), pad(reject, split, lens)\n",
    "\n",
    "\n",
    "get_batch_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9673b3",
   "metadata": {},
   "source": [
    "为什么在加载 model_dpo_ref 时将其转换到 train 模式？\n",
    "\n",
    "保持前向传播行为一致： \n",
    "模型在训练模式（train mode）和评估模式（eval mode）下的行为可能不同，例如 dropout 和 batch normalization 等层在训练时会有随机性或统计更新。如果参考模型与当前模型的前向传播行为不同，就会导致两者输出的概率分布不一致，从而影响 KL 散度的计算。\n",
    "\n",
    "与当前模型一致的训练状态：\n",
    "在 DPO 方法中，参考模型用于为当前模型提供一个固定的基准。虽然参考模型的参数不更新，但在训练过程中，保持两者在相同的模式下可以使得它们在相同训练条件下输出，从而使得对比更准确。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b14b5c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3611/4021970835.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_dpo = torch.load('gen.model')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3611/4021970835.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_dpo_ref = torch.load('gen.model')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ModelGEN(\n",
       "  (feature): LlamaModel(\n",
       "    (embed_tokens): Embedding(22, 64)\n",
       "    (layers): ModuleList(\n",
       "      (0-3): 4 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (k_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (v_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (o_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (up_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (down_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((64,), eps=1e-06)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((64,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((64,), eps=1e-06)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (fc_out): Linear(in_features=64, out_features=22, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dpo = torch.load('gen.model')\n",
    "model_dpo.to(device)\n",
    "model_dpo.train()  # 设置为训练模式\n",
    "\n",
    "model_dpo_ref = torch.load('gen.model')\n",
    "model_dpo_ref.to(device)\n",
    "model_dpo_ref.train()  # 设置为训练模式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be824e4",
   "metadata": {},
   "source": [
    "联合对数概率是通过对模型每个时间步生成正确 token 的对数概率求和而得到的, 对每个样本来说，它等于:\n",
    "\n",
    "$$\n",
    "\\log P(y\\mid x)=\\sum_{t}\\log P(y_t\\mid y_{<t}, x)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c35e3b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-36.3975, -41.2956, -38.5050, -33.2261, -39.9436, -33.6403, -38.7957,\n",
       "        -33.8615, -35.3346, -36.6786, -33.2887, -41.1539, -36.2859, -33.5000,\n",
       "        -35.1207, -42.6176, -32.4942, -40.6792, -34.1383, -36.3579, -32.3941,\n",
       "        -34.6535, -42.4205, -35.9236, -36.9693, -33.9081, -39.1094, -33.1617,\n",
       "        -38.3072, -35.2617, -33.2931, -32.9153, -34.7415, -34.6575, -37.3955,\n",
       "        -35.3297, -37.8426, -35.4901, -40.4166, -33.1556, -32.6194, -35.3885,\n",
       "        -31.9937, -39.4524, -32.2923, -32.0736, -29.5068, -34.6358, -35.5317,\n",
       "        -37.8613, -34.9341, -35.3608, -33.2361, -35.2435, -40.4090, -35.1232,\n",
       "        -35.7186, -32.2918, -34.1016, -32.7183, -32.1375, -35.9033, -38.8661,\n",
       "        -31.4803], device='cuda:0', grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' 计算每个词的概率, 计算模型对两种不同回答 choice 与 reject 的联合生成概率的对数值, 并返回它们之间的差异 '\n",
    "def get_prob_log(model, choice, reject):\n",
    "    b = choice['input_ids'].shape[0]  # b=64\n",
    "\n",
    "    # 合并两部分输入,同时计算以提高效率\n",
    "    # [2b, 30]\n",
    "    input_ids = torch.cat([choice['input_ids'], reject['input_ids']], dim=0)\n",
    "    attention_mask = torch.cat([choice['attention_mask'], reject['attention_mask']], dim=0)\n",
    "    label = torch.cat([choice['label'], reject['label']], dim=0)\n",
    "\n",
    "    # [2b, 30, 22]\n",
    "    out = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    # print(out.shape) -> torch.Size([128, 30, 22])\n",
    "    # -> (batch_size, seq_len, vocab_size)\n",
    "\n",
    "    # 偏移以对齐\n",
    "    # 为了计算生成下一个词的概率, 需要对输出和标签进行时间步的对齐\n",
    "    label = label[:, 1:]  # [2b, 29]\n",
    "    out = out[:, :-1]  # [2b, 29, 22]\n",
    "\n",
    "    # 取所有字的预测概率, 因为要求联合概率, 所以取对数\n",
    "    # 在 词表 维度做 softmax 得到预测概率分布, 加上一个很小的常数防止 log(0), 然后取对数\n",
    "    # 这一步得到的是每个时间步、每个 token 的对数概率\n",
    "    out = (out.softmax(dim=2) + 1e-8).log()\n",
    "\n",
    "    # 取预测到 label 的概率\n",
    "    # 索引不能是负数, 所以这里把负数置0\n",
    "    # 将真实标签扩展一个维度, 然后使用 gather 操作, 从 out 中选出每个时间步对应真实 token 的对数概率\n",
    "    index = label.clone().unsqueeze(2)  # -> torch.Size([128, 29, 1]) \n",
    "    index[index == -100] = 0\n",
    "    prob = out.gather(2, index=index).squeeze(2)  # -> (2b, seq_len-1): torch.Size([128, 29])\n",
    "    \n",
    "    # 只取答案部分的loss, 筛选后, 所有答案的概率对数求和\n",
    "    prob = (prob * (label != -100)).sum(1)\n",
    "\n",
    "    # choice 和 reject 的预测概率求差\n",
    "    # 前 b 是 choice, 后 b 是 reject\n",
    "    # L_w - L_l  = \\log\\pi_\\theta(y_w|x) - \\log\\pi_\\theta(y_l|x)\n",
    "    return prob[:b] - prob[b:]\n",
    "\n",
    "get_prob_log(model_dpo, *get_batch_data())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ce7dab",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\mathcal{L}_{\\text{DPO}}(\\pi_{\\theta};\\pi_{\\text{ref}}) &=-\\mathbb{E}_{x,y_{w},y_{l}\\sim \\mathcal{D}}\\left[ \\log\\sigma\\left( \\beta \\log \\frac{\\pi_{\\theta}(y_{w}|x)}{\\pi_{\\text{ref}}(y_{w}|x)} - \\beta \\log \\frac{\\pi_{\\theta}(y_{l}|x)}{\\pi_{\\text{ref}}(y_{l}|x)} \\right) \\right]  \\\\\n",
    "&= -\\mathbb{E}_{x,y_{w},y_{l}\\sim \\mathcal{D}}\\left[ \\log\\sigma \\bigg(\\beta \\right( ( \\log\\pi (y_w|x) - \\log\\pi (y_l|x) ) -  ( \\log\\pi_{\\text{ref}}(y_w|x) - \\log\\pi_{\\text{ref}}(y_l|x) ) \\left)\\bigg) \\right] \n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb049323",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 S38.66=-54.10+63.5/-991.90E\n",
      "2000 S-0.95=10.74/-8.48+-1.67E\n",
      "4000 S-784.15=58.70*-13.22+47.97E\n",
      "6000 S24.08=-54.01/-81.17+22.06E\n",
      "8000 S3100.93=-50.69*-65.81+-48.18E\n",
      "10000 S100.26=78.32+69.76+4.49E\n",
      "12000 S-2464.63=-42.03*55.97+-23.99E\n",
      "14000 S-113.92=-22.43-79.28+-17.07E\n",
      "16000 S122.67=77.95--14.93+34.23E\n",
      "18000 S-22.73=-37.63-6.48+34.90E\n",
      "20000 S-13.32=-7.20+-42.35+39.57E\n",
      "22000 S-43.89=-1.13+1.92+-46.45E\n",
      "24000 S-110.33=-57.24-44.87+-8.08E\n",
      "26000 S-0.17=34.01/-57.09+-0.96E\n",
      "28000 S-2.30=-26.17--15.81+12.24E\n",
      "30000 S-53.90=15.98+-87.02+19.26E\n",
      "32000 S251.24=-16.03*-17.50+0.25E\n",
      "34000 S92.52=24.50--15.78+50.16E\n",
      "36000 S5397.76=58.27*92.93+64.71E\n",
      "38000 S-1317.96=-70.50*19.17+-3.34E\n",
      "40000 S4697.70=47.65*88.29+64.41E\n",
      "42000 S-50.51=-84.35+48.00+-11.67E\n",
      "44000 S10.44=-98.18/58.12+12.47E\n",
      "46000 S-534.05=36.95*-15.62+13.51E\n",
      "48000 S1136.50=16.76*68.07+39.75E\n",
      "50000 S18.31=56.96+69.55+-99.93E\n",
      "52000 S130.28=23.66--68.28+35.58E\n",
      "54000 S-28.05=9.51/88.61+-28.36E\n",
      "56000 S4954.76=62.31*82.60+-28.61E\n",
      "58000 S-15.25=-39.11+80.21+-58.08E\n",
      "60000 S-135.67=43.73-86.72+-85.82E\n",
      "62000 S77.15=50.86--27.22+-4.97E\n",
      "64000 S1894.86=32.88*56.08+-60.09E\n",
      "66000 S-56.72=-6.39-20.75+-29.07E\n",
      "68000 S-25.00=63.34/-72.00+-24.78E\n",
      "70000 S-48.26=-60.99/-63.79+-49.30E\n",
      "72000 S-2630.51=59.11*-44.81+-73.00E\n",
      "74000 S-52.78=-98.13--2.45+43.43E\n",
      "76000 S-74.13=42.45/78.71+-74.56E\n",
      "78000 S81.09=24.64/52.92+80.13E\n",
      "80000 S1937.56=33.97*55.50+-71.16E\n",
      "82000 S-21.65=28.02--8.33+-53.72E\n",
      "84000 S1041.53=-55.92*-19.06+80.66E\n",
      "86000 S-19.74=-70.46--60.19+-10.68E\n",
      "88000 S54.85=-62.96+34.50+87.99E\n",
      "90000 S-180.18=-19.03-68.87+-92.22E\n",
      "92000 S68.91=35.04+63.85+-29.23E\n",
      "94000 S-183.35=-74.16+-86.72+-23.09E\n",
      "96000 S-74.66=5.31-1.67+-83.12E\n",
      "98000 S87.23=-40.96--80.23+51.96E\n",
      "100000 S-208.98=-72.26-39.19+-97.06E\n",
      "102000 S3713.70=72.95*50.49+-5.32E\n",
      "104000 S12.33=-46.22/73.07+12.74E\n",
      "106000 S-940.12=14.15*-69.52+65.33E\n",
      "108000 S4975.49=88.07*57.89+35.26E\n",
      "110000 S-50.20=-77.44/25.60+-47.56E\n",
      "112000 S-103.94=-75.69-2.32+-22.20E\n",
      "114000 S108.30=61.53+32.75+16.56E\n",
      "116000 S47.74=2.94/72.51+47.26E\n",
      "118000 S-941.29=46.03*-20.96+2.85E\n",
      "120000 S102.09=-33.91--57.29+77.17E\n",
      "122000 S-6374.64=78.50*-80.31+39.27E\n",
      "124000 S-53.70=17.97-18.43+-51.30E\n",
      "126000 S-1694.48=35.00*-48.92+20.19E\n",
      "128000 S6.50=-4.03+-39.95+49.85E\n",
      "130000 S83.83=88.13/34.39+81.26E\n",
      "132000 S-2356.89=50.96*-46.96+44.42E\n",
      "134000 S-32.67=60.18/-69.36+-31.44E\n",
      "136000 S101.45=-61.75--95.46+67.45E\n",
      "138000 S-2.92=-11.20+14.07+-4.78E\n",
      "140000 S26.26=-74.24*1.61+47.30E\n",
      "142000 S11.46=-88.15--30.01+72.21E\n",
      "144000 S3165.81=-34.31*-93.19+-38.59E\n",
      "146000 S1654.52=27.69*57.47+55.26E\n",
      "148000 S35.38=-18.73-53.06+99.05E\n",
      "150000 S-7292.61=-68.81*99.59+-90.33E\n",
      "152000 S-4283.74=49.02*-89.76+6.61E\n",
      "154000 S-6599.85=91.86*-74.25+77.29E\n",
      "156000 S2319.53=-34.68*-67.83+-36.94E\n",
      "158000 S60.17=-17.32--26.54+52.13E\n",
      "160000 S-4987.18=-74.62*69.54+75.35E\n",
      "162000 S-86.66=-92.10--48.74+-38.30E\n",
      "164000 S46.53=-82.70/-10.80+37.42E\n",
      "166000 S113.08=-1.51*-52.63+4.96E\n",
      "168000 S4761.82=-49.86*-94.41+15.53E\n",
      "170000 S-3963.44=-84.65*48.91+98.79E\n",
      "172000 S-13.76=-21.47/7.04+-8.16E\n",
      "174000 S111.81=59.37+-35.04+85.34E\n",
      "176000 S-24.55=76.06+-88.82+-10.70E\n",
      "178000 S59.41=60.14/-80.25+60.65E\n",
      "180000 S2515.90=-51.63*-48.06+-89.90E\n",
      "182000 S6693.68=75.60*87.90+-33.50E\n",
      "184000 S8.92=31.69-77.72+53.33E\n",
      "186000 S89.92=-57.92--74.63+73.20E\n",
      "188000 S-91.46=-55.70-81.24+45.99E\n",
      "190000 S8.88=15.19/-70.93+9.90E\n",
      "192000 S6.75=-55.67/63.18+7.02E\n",
      "194000 S-75.81=97.62/-9.63+-66.24E\n",
      "196000 S-155.66=7.17+-61.49+-99.06E\n",
      "198000 S-77.11=9.88/-34.84+-76.56E\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "    model_dpo.parameters(),\n",
    "    lr=1e-4,\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-8\n",
    ")\n",
    "\n",
    "for i in range(20_0000):\n",
    "    choice, reject = get_batch_data()\n",
    "\n",
    "    # 两个模型分别计算概率对数\n",
    "    prob_log = get_prob_log(model_dpo, choice, reject)  # L_w - L_l  = \\log\\pi_\\theta(y_w|x) - \\log\\pi_\\theta(y_l|x)\n",
    "    with torch.no_grad():\n",
    "        prob_log_ref = get_prob_log(model_dpo_ref, choice, reject)  # # L_w^{\\text{ref}} - L_l^{\\text{ref}}\n",
    "\n",
    "    # 两份概率计算 KL 散度\n",
    "    kl = -0.1 * (prob_log - prob_log_ref)\n",
    "\n",
    "    # 以kl散度计算loss\n",
    "    loss = (kl.sigmoid() + 1e-8).log().mean()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if i % 2000 == 0:\n",
    "        question = tokenizer.get_data(third_number=True)\n",
    "        question = question[:question.index(tokenizer.encoder['=']) + 1]\n",
    "        question = torch.LongTensor(question).unsqueeze(0).to(device)\n",
    "\n",
    "        gen = generate(model_dpo, question)\n",
    "        print(i, tokenizer.decode(gen[0].tolist()))\n",
    "\n",
    "model_dpo.to('cpu')\n",
    "torch.save(model_dpo, 'dpo.model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
